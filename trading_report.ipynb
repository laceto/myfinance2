{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading Report — Italian Equity Signals\n",
    "\n",
    "Reads `data/results/it/analysis_results.parquet` (produced by `analyze_stock.py`) and surfaces:\n",
    "- **Actionable trades**: Enter / Exit signals from the last 4 trading days\n",
    "- **Per-signal status**: latest active signals per strategy\n",
    "- **Full dashboard**: flat DataFrame exported to Excel\n",
    "\n",
    "> Prerequisites: run `analyze_stock.py` first so stop-loss columns are present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# UTF-8 so algoshort unicode symbols (✓ etc.) render correctly on Windows\n",
    "sys.stdout.reconfigure(encoding=\"utf-8\")\n",
    "sys.stderr.reconfigure(encoding=\"utf-8\")\n",
    "\n",
    "from algoshort.trading_summary import (\n",
    "    get_multi_symbol_summary,\n",
    "    print_multi_symbol_summary,\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress internal HOLD LONG / HOLD SHORT noise from algoshort\n",
    "logging.getLogger(\"algoshort\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"algoshort.trading_summary\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Paths ──────────────────────────────────────────────────────────────────\n",
    "RESULTS_PATH   = Path(\"./data/results/it/analysis_results.parquet\")\n",
    "DASHBOARD_PATH = Path(\"./data/results/it/trading_dashboard.xlsx\")\n",
    "\n",
    "# Position-sizing column suffixes written by algoshort.position_sizing\n",
    "_PS_SUFFIXES: dict[str, str] = {\n",
    "    \"equal\":    \"_shares_equal\",\n",
    "    \"constant\": \"_shares_constant\",\n",
    "    \"concave\":  \"_shares_concave\",\n",
    "    \"convex\":   \"_shares_convex\",\n",
    "}\n",
    "\n",
    "# How many recent trading days to include in the actionable summary\n",
    "LOOKBACK_DAYS = 4\n",
    "LOOKBACK_BARS = 5  # bars passed to get_multi_symbol_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(path: Path) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"Load the combined parquet and split it into per-symbol DataFrames.\"\"\"\n",
    "    log.info(\"Loading results from %s\", path)\n",
    "    df = pd.read_parquet(path)\n",
    "    if \"date\" in df.columns:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    data_dict = {symbol: grp.copy() for symbol, grp in df.groupby(\"symbol\")}\n",
    "    log.info(\"Loaded %d symbols.\", len(data_dict))\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "data_dict = load_results(RESULTS_PATH)\n",
    "\n",
    "first_df = next(iter(data_dict.values()))\n",
    "print(f\"Symbols loaded : {len(data_dict)}\")\n",
    "print(f\"Rows per symbol: ~{len(first_df)}\")\n",
    "print(f\"Date range     : {first_df['date'].min().date()} → {first_df['date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Detect Signal Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_signal_columns(df: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"\n",
    "    Return column names that have a matching <col>_stop_loss counterpart.\n",
    "    This is the reliable marker distinguishing primary trading signals from\n",
    "    derived metrics (returns, cumulative P&L, etc.).\n",
    "    \"\"\"\n",
    "    cols = set(df.columns)\n",
    "    return sorted(c for c in cols if f\"{c}_stop_loss\" in cols)\n",
    "\n",
    "\n",
    "def build_position_cols(signal: str, available: set[str]) -> dict[str, str] | None:\n",
    "    \"\"\"Build position_cols mapping, keeping only columns that actually exist.\"\"\"\n",
    "    mapping = {\n",
    "        label: f\"{signal}{suffix}\"\n",
    "        for label, suffix in _PS_SUFFIXES.items()\n",
    "        if f\"{signal}{suffix}\" in available\n",
    "    }\n",
    "    return mapping or None\n",
    "\n",
    "\n",
    "available_cols  = set(first_df.columns)\n",
    "signal_columns  = detect_signal_columns(first_df)\n",
    "\n",
    "if not signal_columns:\n",
    "    stop_loss_present = sorted(c for c in available_cols if c.endswith(\"_stop_loss\"))\n",
    "    raise RuntimeError(\n",
    "        f\"No signal columns detected (need matching <col>_stop_loss).\\n\"\n",
    "        f\"stop_loss cols found : {stop_loss_present}\\n\"\n",
    "        f\"Re-run analyze_stock.py to regenerate results with stop-loss columns.\"\n",
    "    )\n",
    "\n",
    "print(f\"Detected {len(signal_columns)} signal columns:\")\n",
    "for col in signal_columns:\n",
    "    has_sizing = any(f\"{col}{s}\" in available_cols for s in _PS_SUFFIXES.values())\n",
    "    print(f\"  {col}\" + (\"  [+ position sizing]\" if has_sizing else \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summaries_to_dataframe(summaries: list[dict], signal: str) -> pd.DataFrame:\n",
    "    \"\"\"Flatten get_multi_symbol_summary output into one row per symbol.\"\"\"\n",
    "    rows = []\n",
    "    for s in summaries:\n",
    "        if \"error\" in s:\n",
    "            rows.append({\"signal\": signal, \"ticker\": s[\"ticker\"], \"error\": s[\"error\"]})\n",
    "            continue\n",
    "        row = {\n",
    "            \"signal\":         signal,\n",
    "            \"ticker\":         s[\"ticker\"],\n",
    "            \"last_date\":      pd.to_datetime(s[\"last_date\"]),\n",
    "            \"price\":          s[\"current_price\"],\n",
    "            \"position\":       s[\"position_direction\"],\n",
    "            \"action\":         s[\"trade_action\"],\n",
    "            \"signal_changed\": s[\"signal_changed\"],\n",
    "            \"stop_loss\":      s[\"stop_loss\"],\n",
    "            \"risk_pct\":       s[\"risk_pct\"],\n",
    "        }\n",
    "        for label, shares in s.get(\"position_sizes\", {}).items():\n",
    "            row[f\"shares_{label}\"] = shares\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "all_summaries: dict[str, list[dict]] = {}\n",
    "all_dashboards: list[pd.DataFrame] = []\n",
    "\n",
    "for signal in signal_columns:\n",
    "    position_cols = build_position_cols(signal, available_cols)\n",
    "    summaries = get_multi_symbol_summary(\n",
    "        data_dict=data_dict,\n",
    "        signal_col=signal,\n",
    "        stop_loss_col=f\"{signal}_stop_loss\",\n",
    "        close_col=\"close\",\n",
    "        position_cols=position_cols,\n",
    "        lookback=LOOKBACK_BARS,\n",
    "    )\n",
    "    all_summaries[signal] = summaries\n",
    "    all_dashboards.append(summaries_to_dataframe(summaries, signal))\n",
    "    log.info(\"Signal '%s' done: %d summaries.\", signal, len(summaries))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Full Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard = pd.concat(all_dashboards, ignore_index=True)\n",
    "\n",
    "DASHBOARD_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "dashboard.to_excel(DASHBOARD_PATH, index=False)\n",
    "log.info(\"Dashboard saved → %s  (%d rows)\", DASHBOARD_PATH, len(dashboard))\n",
    "\n",
    "print(f\"Dashboard shape: {dashboard.shape}\")\n",
    "dashboard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Actionable Trades — Last 4 Trading Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = sorted(dashboard[\"last_date\"].unique(), reverse=True)\n",
    "latest_date  = unique_dates[0]\n",
    "cutoff_index = min(LOOKBACK_DAYS - 1, len(unique_dates) - 1)\n",
    "four_days_ago = unique_dates[cutoff_index]\n",
    "\n",
    "is_recent = dashboard[\"last_date\"] >= four_days_ago\n",
    "is_action = dashboard[\"action\"].str.contains(\"Enter|Exit\", case=False, na=False)\n",
    "\n",
    "actionable = (\n",
    "    dashboard[is_recent & is_action]\n",
    "    .sort_values(by=\"last_date\", ascending=False)\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "print(f\"Actionable trades: {four_days_ago.date()} → {latest_date.date()}\")\n",
    "print(f\"Found {len(actionable)} Enter/Exit signals.\\n\")\n",
    "\n",
    "display_cols = [\"last_date\", \"signal\", \"ticker\", \"price\", \"action\", \"stop_loss\", \"risk_pct\"]\n",
    "actionable[display_cols] if not actionable.empty else print(\"No Enter/Exit signals in the last 4 trading days.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Per-Signal Status — Latest Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Active signals on {latest_date.date()}\\n\")\n",
    "\n",
    "for signal in signal_columns:\n",
    "    active = [\n",
    "        s for s in all_summaries[signal]\n",
    "        if pd.to_datetime(s.get(\"last_date\")) == latest_date\n",
    "        and any(act in str(s.get(\"trade_action\", \"\")) for act in [\"Enter\", \"Exit\"])\n",
    "    ]\n",
    "    if active:\n",
    "        print(f\"\\n>>> [ {signal} ]\")\n",
    "        print(\"-\" * 35)\n",
    "        print_multi_symbol_summary(active, detailed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Quick Exploration Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Distribution of actions across all signals ──────────────────────────────\n",
    "dashboard.groupby([\"signal\", \"action\"]).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Filter to a specific ticker across all signals ───────────────────────────\n",
    "TICKER = \"AVIO.MI\"  # ← change me\n",
    "dashboard[dashboard[\"ticker\"] == TICKER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Filter to a specific signal ───────────────────────────────────────────────\n",
    "SIGNAL = signal_columns[0]  # ← change me\n",
    "sig_df = dashboard[dashboard[\"signal\"] == SIGNAL].sort_values(\"action\")\n",
    "sig_df[[\"ticker\", \"price\", \"position\", \"action\", \"stop_loss\", \"risk_pct\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
